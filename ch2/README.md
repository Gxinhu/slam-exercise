# 初识 SLAM 
## 引言
SLAM 是 Simulataneout Localization and Mapping 的缩写，中文译作 “**同时定位与地图构建**“
他是搭建**特定传感器**的主体，在没有**环境先验信息**的情况下，与**运动过程中**建立**环境**的模型，同时估计自己的**运动**。
要想机器人有自主移动的能力，并且进行只有探索，首先它需要知道两件事：
1. 我在什么地方？——定位
2. 周围环境是什么样的？——建图
就相当于机器人需要了解自身的状态（即位置），另一方面也需要了解外在的环境（即地图）。

视觉 SLAM 主要是通过**相机**来解决定位和建图问题，根据工作方式的不同，相机主要分为单目（Monocular）、双目（Stereo）和深度（RGB-D）三大类。
### 单目相机
只使用一个摄像头进行 SLAM 的做法被称为单目 SLAM ， 它使用二维的形式来记录三维的世界。
- pros: 成本低廉
- cons: 尺度不确定性（无法确定物体的真实尺度），平移之后才能计算依靠视差（近处的物体移动快，远处的物体移动慢，极远处几乎不动）来计算深度。
- 缺点的根本原因就是单张图像无法确定深度。
### 双目相机和深度相机
双目相机两个相机之的距离被称之为基线，可以通过基线估算出每个像素的空间位置。
深度相机又被称为 RGB-D 主要使用传感器比如说红外线结构光或者是 Time-of-Flight 原理来估测出物体与相机之间的距离。
- pros：可以依靠单张图像确定距离
- 双目相机 cons：需要大量的计算才能估计每一个像素点的深度，通常还需要 GPU 和 FPGA 设备进行加速。因此在现有的条件下，**计算量**是双目相机的瓶颈。
- 深度相机 cons：虽然相比双目相机要节省计算资源，但是RGB相机具有测量距离窄、噪声大、视野小、易受日光干扰、无法测量投射材质等诸多问题，主要用于室内，室外难以应用。
## 视觉 SLAM 框架的组成部分
![image SLAM框架的组成部分](./docs/2021-11-29_21-04.png)
整个视觉 SLAM 流程包括以下步骤。
1. **传感器信息读取**。在视觉 SLAM 中主要为相机图像信息的读取和预处理。如果在机器人中，还可能有码盘、惯性传感器等信息的读取和同步。
2. **前端视觉里程计（Visual Odometry, VO）**。 视觉里程计的任务是估算相邻图像间相机的运动，以及局部地图的样子。VO被称为**前端**。
3. **后端（非线性）优化（Optimization）**。后端接受不同时刻视觉里程计测量的相机位姿，以及回环检测的信息，对他们进行优化，得到全局一致的轨迹和地图。由于接在 VO 之后，又被称为**后端**。
4. **回环检测（Loop Closure Detection）**。回环检测判断机器人是否到达过先前的位置。如果检查到回环，它会把信息提供给后端进行处理。
5. **建图（Mapping）**。他根据估计的轨迹，建立于任务要求对应的地图。
### Visual Odometry 视觉里程计
### Optimization 后端优化
### Loop Closure 回环检测
### Mapping 地图构建